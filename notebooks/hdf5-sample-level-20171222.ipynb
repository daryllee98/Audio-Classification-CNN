{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keunwoochoi/keras_cropping_layer/blob/master/cnn_cropping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and modify notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from pysndfx import AudioEffectsChain\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from keras.utils import HDF5Matrix\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Modify notebook settings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create paths to data folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the project root directory\n",
    "proj_root = os.path.join(os.pardir)\n",
    "\n",
    "# Save path to the raw metadata file\n",
    "# \"UrbanSound8K.csv\"\n",
    "metadata_file = os.path.join(proj_root,\n",
    "                             \"data\",\n",
    "                             \"raw\",\n",
    "                             \"UrbanSound8K\",\n",
    "                             \"metadata\",\n",
    "                             \"UrbanSound8K.csv\")\n",
    "\n",
    "# Save path to the raw audio files\n",
    "raw_audio_path = os.path.join(proj_root,\n",
    "                             \"data\",\n",
    "                             \"raw\",\n",
    "                             \"UrbanSound8K\",\n",
    "                             \"audio\")\n",
    "\n",
    "# Save path to the raw audio files\n",
    "fold1_path = os.path.join(raw_audio_path,\n",
    "                          \"fold1\")\n",
    "\n",
    "\n",
    "# Save the path to the folder that will contain \n",
    "# the interim data sets for modeling:\n",
    "# /data/interim\n",
    "interim_data_dir = os.path.join(proj_root,\n",
    "                                \"data\",\n",
    "                                \"interim\")\n",
    "\n",
    "\n",
    "# Save the path to the folder that will contain \n",
    "# the interim trash data sets\n",
    "# /data/interim\n",
    "interim_trash_dir = os.path.join(interim_data_dir,\n",
    "                                \"trash\")\n",
    "\n",
    "# Save path to the folder for the\n",
    "# spectrogram arrays that we will generate\n",
    "spectrogram_arrays_path = os.path.join(interim_data_dir,\n",
    "                                       \"spectrogram_arrays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(proj_root, \"src\")\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.format_bytes_size import FormatBytesSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_name = 'metadata_test.csv'\n",
    "new_file_path = os.path.join(interim_data_dir,\n",
    "                             new_file_name)\n",
    "df_test = pd.read_csv(new_file_path, index_col=0)\n",
    "\n",
    "test_len = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_name = 'metadata_train.csv'\n",
    "new_file_path = os.path.join(interim_data_dir,\n",
    "                             new_file_name)\n",
    "df_train = pd.read_csv(new_file_path, index_col=0)\n",
    "\n",
    "train_len = len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process audio files [NEW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_shift_list = [None, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 3.5, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5]\n",
    "\n",
    "pitch_shift_list = [None, -2.0, -1.5, -1.0, -0.5, 2.0, 1.5, 1.0, 0.5]\n",
    "\n",
    "pitch_shift_list_len = len(pitch_shift_list)\n",
    "\n",
    "total_tran_len = train_len * pitch_shift_list_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_tuple:\t\t (1, 88200, 1)\n",
      "X_test_shape_tuple:\t (1374, 88200, 1)\n",
      "X_train_shape_tuple:\t (51660, 88200, 1)\n",
      "y_test_shape_tuple:\t (1374, 1)\n",
      "y_train_shape_tuple:\t (51660, 1)\n"
     ]
    }
   ],
   "source": [
    "seconds = 4\n",
    "\n",
    "chunk_tuple = (1, (global_sr * seconds), 1)\n",
    "\n",
    "X_test_shape_tuple = (test_len, (global_sr * seconds), 1)\n",
    "X_train_shape_tuple = (total_tran_len, (global_sr * seconds), 1)\n",
    "\n",
    "y_test_shape_tuple = (test_len, 1)\n",
    "y_train_shape_tuple = (total_tran_len, 1)\n",
    "\n",
    "print('chunk_tuple:\\t\\t', chunk_tuple)\n",
    "print('X_test_shape_tuple:\\t', X_test_shape_tuple)\n",
    "print('X_train_shape_tuple:\\t', X_train_shape_tuple)\n",
    "print('y_test_shape_tuple:\\t', y_test_shape_tuple)\n",
    "print('y_train_shape_tuple:\\t', y_train_shape_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/interim/trash/sample-level-augmented.hdf5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_file_name = 'sample-level-augmented.hdf5'\n",
    "hdf5_path = os.path.join(interim_trash_dir, hdf5_file_name)\n",
    "hdf5_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_path, 'w') as f:\n",
    "    \n",
    "    f.create_dataset(\"X_test_dset\", \n",
    "                     shape=X_test_shape_tuple, \n",
    "                     dtype='float32', # data=np.zeros(X_test_shape_tuple, dtype='float32'),\n",
    "                     chunks=chunk_tuple,\n",
    "                     compression=\"gzip\")\n",
    "    \n",
    "    f.create_dataset(\"X_train_dset\", \n",
    "                     shape=X_train_shape_tuple, \n",
    "                     dtype='float32', # data=np.zeros(X_train_shape_tuple, dtype='float32'),\n",
    "                     chunks=chunk_tuple,\n",
    "                     compression=\"gzip\")\n",
    "    \n",
    "    f.create_dataset(\"y_test_dset\", \n",
    "                     shape=y_test_shape_tuple, \n",
    "                     dtype='int8', # data=np.zeros(y_test_shape_tuple, dtype='int8'),\n",
    "                     compression=\"gzip\")\n",
    "    \n",
    "    f.create_dataset(\"y_train_dset\", \n",
    "                     shape=y_train_shape_tuple, \n",
    "                     dtype='int8', # data=np.zeros(y_train_shape_tuple, dtype='int8'),\n",
    "                     compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:\t 1,374  of  1,374  (100.0%) \t\tSpace: 429.28 MB\r"
     ]
    }
   ],
   "source": [
    "#Populate X_test_dset and y_test_dset in hdf5_path\n",
    "\n",
    "count = 0\n",
    "\n",
    "for index, (_, row) in enumerate(df_test.iterrows()):\n",
    "\n",
    "    sys.stdout.write(\"\\rCount:\\t {:,}  of  \".format(count) + \\\n",
    "                     \"{:,}  \".format(y_test_shape_tuple[0]) + \\\n",
    "                     \"({:.1f}%) \\t\\tSpace: \".format(100 * (count / y_test_shape_tuple[0])) + \\\n",
    "                     FormatBytesSize(os.path.getsize(hdf5_path)))\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write('\\r')\n",
    "    \n",
    "    # Save path to the raw audio files\n",
    "    fold_name = 'fold' + str(row['fold'])\n",
    "    fold_path = os.path.join(raw_audio_path,\n",
    "                             fold_name)\n",
    "    \n",
    "    # Full path to the audio_file\n",
    "    audio_file = row['slice_file_name']\n",
    "    audio_path = os.path.join(fold_path,\n",
    "                              audio_file)\n",
    "    \n",
    "    # Load the .wav audio_file\n",
    "    aud_array, _ = librosa.load(audio_path, sr=global_sr)\n",
    "\n",
    "    classID = row['classID']\n",
    "    \n",
    "    # Write to the hdf5 file\n",
    "    with h5py.File(hdf5_path, \"r+\") as f:\n",
    "        # X_test\n",
    "        dset = f['X_test_dset']    \n",
    "\n",
    "        # limit tensor length of 88200\n",
    "        dset[count,:,] = aud_array[np.newaxis, :88200, np.newaxis]\n",
    "        \n",
    "        # y_test\n",
    "        dset = f['y_test_dset']    \n",
    "        dset[count,:] = row['classID']\n",
    "\n",
    "    count += 1   \n",
    "\n",
    "sys.stdout.write(\"\\rCount:\\t {:,}  of  \".format(count) + \\\n",
    "                 \"{:,}  \".format(y_test_shape_tuple[0]) + \\\n",
    "                 \"({:.1f}%) \\t\\tSpace: \".format(100 * (count / y_test_shape_tuple[0])) + \\\n",
    "                 FormatBytesSize(os.path.getsize(hdf5_path)))\n",
    "sys.stdout.flush()\n",
    "sys.stdout.write('\\r')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:\t 51,660  of  51,660  (100.0%) \t\tSpace: 16.16 GB\r"
     ]
    }
   ],
   "source": [
    "#Populate X_train_dset and y_train_dset in hdf5_path\n",
    "\n",
    "count = 0\n",
    "\n",
    "for index, (_, row) in enumerate(df_train.iterrows()):\n",
    "    \n",
    "    sys.stdout.write(\"\\rCount:\\t {:,}  of  \".format(count) + \\\n",
    "                     \"{:,}  \".format(y_train_shape_tuple[0]) + \\\n",
    "                     \"({:.1f}%) \\t\\tSpace: \".format(100 * (count / y_train_shape_tuple[0])) + \\\n",
    "                     FormatBytesSize(os.path.getsize(hdf5_path)))        \n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write('\\r')\n",
    "    \n",
    "    # Save path to the raw audio files\n",
    "    fold_name = 'fold' + str(row['fold'])\n",
    "    fold_path = os.path.join(raw_audio_path,\n",
    "                             fold_name)\n",
    "    \n",
    "    # Full path to the audio_file\n",
    "    audio_file = row['slice_file_name']\n",
    "    audio_path = os.path.join(fold_path,\n",
    "                              audio_file)\n",
    "    \n",
    "    # Load the .wav audio_file\n",
    "    aud_array, _ = librosa.load(audio_path, sr=global_sr)\n",
    "\n",
    "    classID = row['classID']\n",
    "    \n",
    "    \n",
    "    for ps in pitch_shift_list:\n",
    "\n",
    "        aud_array_aug = aud_array\n",
    "\n",
    "        # Pitch shift\n",
    "        if ps is not None:\n",
    "            aud_array_aug = librosa.effects.pitch_shift(aud_array_aug, global_sr, n_steps=ps)\n",
    "\n",
    "\n",
    "        # Write to the hdf5 file\n",
    "        with h5py.File(hdf5_path, \"r+\") as f:\n",
    "            # X_train\n",
    "            dset = f['X_train_dset']    \n",
    "\n",
    "            # limit tensor length of 88200\n",
    "            dset[count,:,] = aud_array_aug[np.newaxis, :88200, np.newaxis]\n",
    "\n",
    "            # y_train\n",
    "            dset = f['y_train_dset']    \n",
    "            dset[count,:] = row['classID']\n",
    "\n",
    "        count += 1   \n",
    "    \n",
    "sys.stdout.write(\"\\rCount:\\t {:,}  of  \".format(count) + \\\n",
    "                 \"{:,}  \".format(y_train_shape_tuple[0]) + \\\n",
    "                 \"({:.1f}%) \\t\\tSpace: \".format(100 * (count / y_train_shape_tuple[0])) + \\\n",
    "                 FormatBytesSize(os.path.getsize(hdf5_path)))        \n",
    "sys.stdout.flush()\n",
    "sys.stdout.write('\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create objects for X_train, y_train, X_test, & y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = HDF5Matrix(hdf5_path, \n",
    "                     'X_train_dset')\n",
    "\n",
    "y_train = HDF5Matrix(hdf5_path, \n",
    "                     'y_train_dset')\n",
    "\n",
    "X_test = HDF5Matrix(hdf5_path, \n",
    "                     'X_test_dset')\n",
    "\n",
    "y_test = HDF5Matrix(hdf5_path, \n",
    "                     'y_test_dset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51660, 88200, 1)\n",
      "(1374, 88200, 1)\n",
      "(51660, 1)\n",
      "(1374, 1)\n",
      "(51660, 10)\n",
      "(1374, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... Have ResNext1D infer classes=Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make targets fuzzy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
